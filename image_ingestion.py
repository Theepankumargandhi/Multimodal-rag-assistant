import os
from pathlib import Path
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.docstore.document import Document
from config import IMAGE_PATH, VECTOR_DB_PATH

# CLIP model for image embeddings
CLIP_MODEL = "sentence-transformers/clip-ViT-B-32"
embeddings = HuggingFaceEmbeddings(model_name=CLIP_MODEL)

def ingest_images(folder_path):
    image_files = list(Path(folder_path).glob("*.jpg")) + list(Path(folder_path).glob("*.png"))
    documents = []

    for img_file in image_files:
        try:
            documents.append(Document(
                page_content=str(img_file.resolve()),  # storing path, embedding will be generated by CLIP
                metadata={
                    "source": img_file.name,
                    "path": str(img_file.resolve()),
                    "source_type": "Image"
                }
            ))
        except Exception as e:
            print(f"[!] Failed to process {img_file.name}: {e}")

    if not documents:
        print(" No images found to ingest!")
        return

    # Store images in a separate Chroma collection
    image_vector_db_path = os.path.join(VECTOR_DB_PATH, "image_db")
    os.makedirs(image_vector_db_path, exist_ok=True)

    vectorstore = Chroma(
        persist_directory=image_vector_db_path,
        embedding_function=embeddings
    )
    vectorstore.add_documents(documents)
    vectorstore.persist()

    print(f" Ingested {len(documents)} image(s) into ChromaDB â†’ {image_vector_db_path}")

if __name__ == "__main__":
    ingest_images(IMAGE_PATH)
